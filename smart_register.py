#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½å£°çº¹æ³¨å†Œç³»ç»Ÿ v4.0
æ”¯æŒéŸ³é¢‘è´¨é‡ç›‘æ§ã€å®æ—¶åé¦ˆã€å¤šç§å½•éŸ³æ¨¡å¼
"""

import os
import sys
import time
import tempfile
import numpy as np
import soundfile as sf
from typing import List, Optional, Tuple, Dict
import threading

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

from speaker import ECAPATDNNRecognizer
from config import SAMPLE_RATE, MIN_ENROLLMENT_SAMPLES, MIC_DEVICE_INDEX, SPEAKER_SIMILARITY_THRESHOLD
from enhancement import AudioEnhancer


class AudioQualityAnalyzer:
    """éŸ³é¢‘è´¨é‡åˆ†æå™¨"""

    def __init__(self):
        self.quality_thresholds = {
            'min_rms': 0.08,      # æœ€å°æœ‰æ•ˆRMS
            'max_rms': 0.7,       # æœ€å¤§RMSï¼ˆé¿å…è¿‡è½½ï¼‰
            'min_length': 1.5,    # æœ€çŸ­éŸ³é¢‘é•¿åº¦
            'max_silence': 0.2,   # æœ€å¤§é™éŸ³æ¯”ä¾‹
        }

    def analyze_audio(self, audio_data: bytes) -> Dict:
        """åˆ†æéŸ³é¢‘è´¨é‡"""
        try:
            audio_np = np.frombuffer(audio_data, dtype=np.int16).astype(np.float32) / 32768.0
            length = len(audio_np) / SAMPLE_RATE

            # åŸºæœ¬ç»Ÿè®¡
            rms = np.sqrt(np.mean(audio_np**2))
            peak = np.max(np.abs(audio_np))
            silence_frames = np.sum(np.abs(audio_np) < 0.01)
            silence_ratio = silence_frames / len(audio_np)

            # è´¨é‡è¯„åˆ†
            quality_score = self._calculate_quality_score(rms, length, silence_ratio)

            return {
                'rms': rms,
                'peak': peak,
                'length': length,
                'silence_ratio': silence_ratio,
                'quality_score': quality_score,
                'is_acceptable': quality_score >= 0.6,
                'feedback': self._get_feedback(rms, length, silence_ratio, quality_score)
            }
        except Exception as e:
            return {
                'error': str(e),
                'is_acceptable': False,
                'feedback': f"éŸ³é¢‘åˆ†æå¤±è´¥: {e}"
            }

    def _calculate_quality_score(self, rms: float, length: float, silence_ratio: float) -> float:
        """è®¡ç®—è´¨é‡åˆ†æ•° (0-1)"""
        score = 0.0

        # RMSè¯„åˆ† (40%)
        if rms < self.quality_thresholds['min_rms']:
            rms_score = rms / self.quality_thresholds['min_rms'] * 0.5
        elif rms > self.quality_thresholds['max_rms']:
            rms_score = 0.5
        else:
            # æœ€ä½³èŒƒå›´ 0.15-0.4
            if 0.15 <= rms <= 0.4:
                rms_score = 1.0
            else:
                rms_score = 0.8

        # é•¿åº¦è¯„åˆ† (30%)
        if length < self.quality_thresholds['min_length']:
            length_score = length / self.quality_thresholds['min_length']
        else:
            length_score = min(length / 3.0, 1.0)

        # é™éŸ³è¯„åˆ† (30%)
        silence_score = 1.0 - min(silence_ratio / self.quality_thresholds['max_silence'], 1.0)

        score = 0.4 * rms_score + 0.3 * length_score + 0.3 * silence_score
        return min(max(score, 0.0), 1.0)

    def _get_feedback(self, rms: float, length: float, silence_ratio: float, score: float) -> str:
        """ç”Ÿæˆè´¨é‡åé¦ˆ"""
        feedback = []

        if score >= 0.8:
            feedback.append("âœ… éŸ³é¢‘è´¨é‡ä¼˜ç§€ï¼")
        elif score >= 0.6:
            feedback.append("ğŸ‘ éŸ³é¢‘è´¨é‡è‰¯å¥½")
        else:
            feedback.append("âš ï¸ éŸ³é¢‘è´¨é‡éœ€è¦æ”¹è¿›")

        # å…·ä½“å»ºè®®
        if rms < self.quality_thresholds['min_rms']:
            feedback.append(f"å£°éŸ³å¤ªå° (RMS: {rms:.3f})ï¼Œè¯·é è¿‘éº¦å…‹é£")
        elif rms > self.quality_thresholds['max_rms']:
            feedback.append(f"å£°éŸ³å¤ªå¤§ (RMS: {rms:.3f})ï¼Œè¯·è¿œç¦»éº¦å…‹é£")
        if length < self.quality_thresholds['min_length']:
            feedback.append(f"å½•éŸ³å¤ªçŸ­ ({length:.1f}ç§’)ï¼Œè¯·è¯´å®Œæ•´çš„å¥å­")
        if silence_ratio > self.quality_thresholds['max_silence']:
            feedback.append(f"é™éŸ³å¤ªå¤š ({silence_ratio:.1%})ï¼Œè¯·æ¸…æ™°è¯´è¯")

        return " | ".join(feedback)


class SmartSpeakerRegistrationTool:
    """æ™ºèƒ½å£°çº¹æ³¨å†Œå·¥å…· v4.0"""

    def __init__(self):
        self.recognizer = ECAPATDNNRecognizer()
        self.quality_analyzer = AudioQualityAnalyzer()
        self.enhancer = AudioEnhancer()

        # æ³¨å†Œä¼šè¯çŠ¶æ€
        self.session_stats = {
            'user_id': None,
            'attempts': 0,
            'successful_samples': 0,
            'quality_scores': [],
            'best_quality': 0.0
        }

        print("ğŸ¤ æ™ºèƒ½å£°çº¹æ³¨å†Œå·¥å…· v4.0 åˆå§‹åŒ–å®Œæˆ")
        print("âœ¨ æ”¯æŒå®æ—¶è´¨é‡ç›‘æ§å’Œæ™ºèƒ½å¼•å¯¼")

    def run(self):
        """è¿è¡Œæ³¨å†Œå·¥å…·"""
        self.show_welcome()

        while True:
            choice = self.show_menu()

            if choice == '1':
                self.interactive_registration()
            elif choice == '2':
                self.batch_registration()
            elif choice == '3':
                self.show_registered_users()
            elif choice == '4':
                self.test_recognition()
            elif choice == '5':
                self.user_management()
            elif choice == '6':
                self.quit()
                break
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")

    def show_welcome(self):
        """æ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯"""
        print("\n" + "="*60)
        print("ğŸ¤ æ™ºèƒ½å£°çº¹æ³¨å†Œå·¥å…· v4.0")
        print("åŸºäºECAPA-TDNNçš„å£°çº¹è¯†åˆ«ç³»ç»Ÿ")
        print("="*60)
        print("âœ¨ æ™ºèƒ½è´¨é‡ç›‘æ§")
        print("ğŸ¯ å®æ—¶åé¦ˆå¼•å¯¼")
        print("ğŸ”„ è‡ªåŠ¨é‡è¯•æœºåˆ¶")
        print("ğŸ“Š è¯¦ç»†ç»Ÿè®¡æŠ¥å‘Š")
        print("="*60)

    def show_menu(self):
        """æ˜¾ç¤ºä¸»èœå•"""
        print("\nä¸»èœå•")
        print("-"*40)
        print("1. ğŸ“ äº¤äº’å¼æ³¨å†Œç”¨æˆ·")
        print("2. ğŸ“ æ‰¹é‡æ³¨å†Œï¼ˆä»éŸ³é¢‘æ–‡ä»¶ï¼‰")
        print("3. ğŸ‘¥ æŸ¥çœ‹æ³¨å†Œç”¨æˆ·")
        print("4. ğŸ§ª æµ‹è¯•å£°çº¹è¯†åˆ«")
        print("5. âš™ï¸  ç”¨æˆ·ç®¡ç†")
        print("6. ğŸšª é€€å‡º")
        print("-"*40)

        return input("è¯·é€‰æ‹©åŠŸèƒ½ (1-6): ").strip()

    def interactive_registration(self):
        """æ™ºèƒ½äº¤äº’å¼æ³¨å†Œ"""
        print("\n" + "="*60)
        print("ğŸ¤ æ™ºèƒ½å£°çº¹æ³¨å†Œ - äº¤äº’å¼æ¨¡å¼")
        print("="*60)

        # è¾“å…¥ç”¨æˆ·å
        while True:
            try:
                user_id = input("\nè¯·è¾“å…¥ç”¨æˆ·åï¼ˆå­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿ï¼‰ï¼š").strip()
                if not user_id:
                    print("âŒ ç”¨æˆ·åä¸èƒ½ä¸ºç©º")
                    continue

                # æ£€æŸ¥ç”¨æˆ·åæ ¼å¼
                if not all(c.isalnum() or c == '_' for c in user_id):
                    print("âŒ ç”¨æˆ·ååªèƒ½åŒ…å«å­—æ¯ã€æ•°å­—å’Œä¸‹åˆ’çº¿")
                    continue

                break
            except KeyboardInterrupt:
                print("\nâŒ æ³¨å†Œå–æ¶ˆ")
                return

        self.session_stats['user_id'] = user_id

        # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å·²å­˜åœ¨
        existing_users = self.recognizer.get_user_list()
        if user_id in existing_users:
            count = self.recognizer.get_user_count(user_id)
            print(f"â„¹ï¸  ç”¨æˆ· '{user_id}' å·²å­˜åœ¨ï¼Œå½“å‰æœ‰ {count} ä¸ªæ ·æœ¬")

            choice = input("æ˜¯å¦ç»§ç»­æ·»åŠ æ–°æ ·æœ¬ï¼Ÿ(y/n): ").strip().lower()
            if choice != 'y':
                print("æ³¨å†Œå–æ¶ˆ")
                return

        # å¼€å§‹æ™ºèƒ½æ³¨å†Œæµç¨‹
        self.smart_registration_process(user_id)

    def smart_registration_process(self, user_id: str):
        """æ™ºèƒ½æ³¨å†Œæµç¨‹"""
        print(f"\nğŸ¯ å¼€å§‹ä¸ºç”¨æˆ· '{user_id}' è¿›è¡Œæ™ºèƒ½æ³¨å†Œ")
        print(f"éœ€è¦å½•åˆ¶ {MIN_ENROLLMENT_SAMPLES} ä¸ªé«˜è´¨é‡è¯­éŸ³æ ·æœ¬")
        print("\næ™ºèƒ½æç¤ºï¼š")
        print("â€¢ ç³»ç»Ÿä¼šè‡ªåŠ¨åˆ†æéŸ³é¢‘è´¨é‡")
        print("â€¢ è´¨é‡ä¸ä½³æ—¶ä¼šå»ºè®®é‡æ–°å½•åˆ¶")
        print("â€¢ æ¯ä¸ªæ ·æœ¬å½•åˆ¶3ç§’ï¼Œè¯·è¯´å®Œæ•´çš„å¥å­")

        # ç¤ºä¾‹å¥å­
        sample_sentences = [
            "ä»Šå¤©å¤©æ°”çœŸä¸é”™",
            "æˆ‘å–œæ¬¢å¬éŸ³ä¹",
            "è°¢è°¢ä½ çš„å¸®åŠ©",
            "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å¥å­",
            "è¯­éŸ³è¯†åˆ«æŠ€æœ¯å¾ˆæœ‰è¶£",
            "äººå·¥æ™ºèƒ½å‘å±•å¾ˆå¿«",
            "è¯·é—®ç°åœ¨å‡ ç‚¹äº†",
            "æˆ‘æƒ³å¬ä¸€é¦–æ­Œ",
            "è¿™ä¸ªåŠŸèƒ½å¾ˆå®ç”¨",
            "å£°çº¹è¯†åˆ«çœŸç¥å¥‡"
        ]

        collected_samples = 0
        max_attempts_per_sample = 3

        while collected_samples < MIN_ENROLLMENT_SAMPLES:
            sample_attempt = 0
            sample_accepted = False

            while sample_attempt < max_attempts_per_sample and not sample_accepted:
                sample_attempt += 1

                print(f"\nğŸ“ å½•åˆ¶ç¬¬ {collected_samples + 1}/{MIN_ENROLLMENT_SAMPLES} ä¸ªæ ·æœ¬")
                if sample_attempt > 1:
                    print(f"ğŸ”„ ç¬¬ {sample_attempt} æ¬¡å°è¯•")

                # æ˜¾ç¤ºå»ºè®®å¥å­
                if collected_samples < len(sample_sentences):
                    print(f"ğŸ’¬ å»ºè®®å¥å­ï¼š'{sample_sentences[collected_samples]}'")
                else:
                    print("ğŸ’¬ è¯·è¯´ä»»æ„ä¸€å¥è‡ªç„¶çš„è¯")

                print("\nè¯·é€‰æ‹©å½•éŸ³æ¨¡å¼:")
                print("1. ğŸ¤ çœŸå®å½•éŸ³ï¼ˆæ¨èï¼‰")
                print("2. ğŸ”Š æµ‹è¯•éŸ³é¢‘ï¼ˆç”¨äºè°ƒè¯•ï¼‰")
                print("3. â­ï¸ è·³è¿‡æ­¤æ ·æœ¬")

                choice = input("è¯·é€‰æ‹© (1-3): ").strip()

                if choice == '3':
                    print("â­ï¸ è·³è¿‡æ­¤æ ·æœ¬")
                    sample_accepted = True
                    collected_samples += 1
                    break
                elif choice == '2':
                    # ç”Ÿæˆæµ‹è¯•éŸ³é¢‘
                    frequency = 440 + (collected_samples * 50)
                    audio_data = self.generate_test_audio(frequency=frequency, duration=3.0)
                    quality_info = {'is_acceptable': True, 'quality_score': 0.8, 'feedback': 'æµ‹è¯•éŸ³é¢‘ï¼ˆè´¨é‡å›ºå®šï¼‰'}
                    print("âœ… å·²ç”Ÿæˆæµ‹è¯•éŸ³é¢‘")
                elif choice == '1':
                    # çœŸå®å½•éŸ³
                    audio_data, quality_info = self.record_audio_with_quality_check(duration=3.0)

                    if audio_data is None:
                        print(f"âŒ å½•éŸ³å¤±è´¥: {quality_info.get('error', 'æœªçŸ¥é”™è¯¯')}")
                        if sample_attempt >= max_attempts_per_sample:
                            print("âš ï¸ å¤šæ¬¡å½•éŸ³å¤±è´¥ï¼Œå»ºè®®æ£€æŸ¥éº¦å…‹é£è®¾ç½®")
                        continue

                    # æ˜¾ç¤ºè´¨é‡åé¦ˆ
                    print(f"ğŸ“Š è´¨é‡åˆ†æ: {quality_info['feedback']}")

                    if not quality_info.get('is_acceptable', False):
                        print("âš ï¸ éŸ³é¢‘è´¨é‡ä¸ä½³ï¼Œå»ºè®®é‡æ–°å½•åˆ¶")
                        if input("ä»è¦ä½¿ç”¨æ­¤å½•éŸ³ï¼Ÿ(y/n): ").strip().lower() != 'y':
                            continue
                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°é€‰æ‹©")
                    continue

                # æ³¨å†Œæ ·æœ¬
                success = self.recognizer.enroll_user(user_id, audio_data)
                if success:
                    collected_samples += 1
                    self.session_stats['quality_scores'].append(quality_info.get('quality_score', 0))
                    print(f"âœ… ç¬¬ {collected_samples}/{MIN_ENROLLMENT_SAMPLES} ä¸ªæ ·æœ¬æ³¨å†ŒæˆåŠŸï¼")
                    sample_accepted = True
                else:
                    print("âŒ æ³¨å†Œå¤±è´¥ï¼Œå£°çº¹è¯†åˆ«å™¨å¯èƒ½æœ‰é—®é¢˜")

            if sample_attempt >= max_attempts_per_sample and not sample_accepted:
                print(f"âš ï¸ ç¬¬ {collected_samples + 1} ä¸ªæ ·æœ¬å¤šæ¬¡å°è¯•å¤±è´¥ï¼Œè·³è¿‡")
                collected_samples += 1

            # æ ·æœ¬é—´æš‚åœ
            if collected_samples < MIN_ENROLLMENT_SAMPLES:
                input("\næŒ‰å›è½¦é”®ç»§ç»­å½•åˆ¶ä¸‹ä¸€ä¸ªæ ·æœ¬...")

        # æ³¨å†Œå®Œæˆï¼Œæ˜¾ç¤ºç»Ÿè®¡
        self.show_registration_summary(user_id)

    def record_audio_with_quality_check(self, duration: float = 3.0, show_feedback: bool = True) -> Tuple[Optional[bytes], Dict]:
        """æ™ºèƒ½å½•éŸ³å‡½æ•°ï¼ŒåŒ…å«è´¨é‡åˆ†æ"""
        try:
            import pyaudio

            chunk = 1024
            format = pyaudio.paInt16
            channels = 1
            rate = SAMPLE_RATE

            p = pyaudio.PyAudio()

            # éªŒè¯è®¾å¤‡
            try:
                device_info = p.get_device_info_by_host_api_device_index(0, MIC_DEVICE_INDEX)
                if device_info.get('maxInputChannels') <= 0:
                    return None, {'error': f'è®¾å¤‡ {MIC_DEVICE_INDEX} æ²¡æœ‰è¾“å…¥é€šé“'}
                if show_feedback:
                    print(f"ğŸ¤ ä½¿ç”¨è®¾å¤‡: {device_info['name']} (ç´¢å¼•: {MIC_DEVICE_INDEX})")
            except Exception as e:
                return None, {'error': f'æ— æ³•è®¿é—®è®¾å¤‡ {MIC_DEVICE_INDEX}: {e}'}

            # æ‰“å¼€éŸ³é¢‘æµ
            stream = p.open(
                format=format,
                channels=channels,
                rate=rate,
                input=True,
                input_device_index=MIC_DEVICE_INDEX,
                frames_per_buffer=chunk
            )

            print(f"ğŸ™ï¸ å¼€å§‹å½•éŸ³ {duration} ç§’...")
            print("è¯·æ¸…æ™°åœ°è¯´å‡ºå¥å­ï¼Œä¿æŒè‡ªç„¶è¯­é€Ÿ")
            print("ğŸ’¡ æç¤ºï¼šä¿æŒ15-30cmè·ç¦»ï¼ŒéŸ³é‡é€‚ä¸­")

            frames = []

            # æ˜¾ç¤ºè¿›åº¦æ¡
            total_chunks = int(duration * SAMPLE_RATE / chunk)
            for i in range(total_chunks):
                data = stream.read(chunk)
                frames.append(data)

                # æ¯0.5ç§’æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
                if i % int(0.5 * SAMPLE_RATE / chunk) == 0:
                    progress = (i + 1) / total_chunks
                    bar_length = 20
                    filled = int(bar_length * progress)
                    bar = "â–ˆ" * filled + "â–‘" * (bar_length - filled)
                    print(f"\râ±ï¸ å½•éŸ³è¿›åº¦: [{bar}] {progress:.1%}", end="", flush=True)

            print(" âœ…")

            stream.stop_stream()
            stream.close()
            p.terminate()

            # åˆå¹¶éŸ³é¢‘æ•°æ®
            audio_data = b''.join(frames)

            # åˆ†æéŸ³é¢‘è´¨é‡
            quality_info = self.quality_analyzer.analyze_audio(audio_data)

            return audio_data, quality_info

        except Exception as e:
            print(f"âŒ å½•éŸ³è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return None, {'error': str(e)}

    def show_registration_summary(self, user_id: str):
        """æ˜¾ç¤ºæ³¨å†Œæ€»ç»“"""
        print(f"\nğŸ‰ æ™ºèƒ½æ³¨å†Œå®Œæˆï¼")
        print("="*50)

        final_count = self.recognizer.get_user_count(user_id)
        print(f"ğŸ‘¤ ç”¨æˆ·: {user_id}")
        print(f"ğŸ“Š æ³¨å†Œæ ·æœ¬æ•°: {final_count}")

        if self.session_stats['quality_scores']:
            avg_quality = np.mean(self.session_stats['quality_scores'])
            best_quality = np.max(self.session_stats['quality_scores'])

            print(f"ğŸ“ˆ å¹³å‡è´¨é‡åˆ†æ•°: {avg_quality:.2f}/1.0")
            print(f"ğŸ† æœ€ä½³è´¨é‡åˆ†æ•°: {best_quality:.2f}/1.0")

            if avg_quality >= 0.8:
                print("ğŸ¯ æ³¨å†Œè´¨é‡: ä¼˜ç§€")
            elif avg_quality >= 0.6:
                print("ğŸ‘ æ³¨å†Œè´¨é‡: è‰¯å¥½")
            else:
                print("âš ï¸ æ³¨å†Œè´¨é‡: éœ€è¦æ”¹è¿›")

        print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
        print("â€¢ ç°åœ¨å¯ä»¥æµ‹è¯•å£°çº¹è¯†åˆ«äº†")
        print("â€¢ å»ºè®®åœ¨ä¸åŒç¯å¢ƒä¸‹å¤šæµ‹è¯•å‡ æ¬¡")
        print("â€¢ å®šæœŸæ›´æ–°æ³¨å†Œæ ·æœ¬ä»¥æé«˜å‡†ç¡®æ€§")

        # é‡ç½®ä¼šè¯ç»Ÿè®¡
        self.session_stats = {
            'user_id': None,
            'attempts': 0,
            'successful_samples': 0,
            'quality_scores': [],
            'best_quality': 0.0
        }

    def generate_test_audio(self, frequency: float = 440.0, duration: float = 3.0) -> bytes:
        """ç”Ÿæˆæµ‹è¯•éŸ³é¢‘"""
        sample_rate = SAMPLE_RATE
        t = np.linspace(0, duration, int(sample_rate * duration), False)

        # ç”Ÿæˆå¸¦æœ‰è°æ³¢çš„éŸ³é¢‘ä¿¡å·
        audio = 0.3 * np.sin(2 * np.pi * frequency * t)
        audio += 0.2 * np.sin(2 * np.pi * frequency * 2 * t)  # äºŒå€é¢‘
        audio += 0.1 * np.sin(2 * np.pi * frequency * 3 * t)  # ä¸‰å€é¢‘

        # æ·»åŠ å°‘é‡å™ªå£°
        audio += 0.05 * np.random.normal(0, 1, len(audio))

        # è½¬æ¢ä¸º16ä½æ•´æ•°
        audio_int16 = (audio * 32767).astype(np.int16)

        return audio_int16.tobytes()

    def batch_registration(self):
        """æ‰¹é‡æ³¨å†ŒåŠŸèƒ½"""
        print("\nğŸ“ æ‰¹é‡æ³¨å†ŒåŠŸèƒ½")
        print("æ­¤åŠŸèƒ½ç”¨äºä»éŸ³é¢‘æ–‡ä»¶æ‰¹é‡æ³¨å†Œç”¨æˆ·")
        print("æš‚æœªå®ç°ï¼Œæ•¬è¯·æœŸå¾…...")

        input("\næŒ‰å›è½¦é”®è¿”å›...")

    def show_registered_users(self):
        """æ˜¾ç¤ºæ³¨å†Œç”¨æˆ·"""
        users = self.recognizer.get_user_list()

        print(f"\nğŸ‘¥ å·²æ³¨å†Œç”¨æˆ· (å…± {len(users)} ä¸ª)")
        print("="*50)

        if not users:
            print("ğŸ“­ æš‚æ— æ³¨å†Œç”¨æˆ·")
            return

        total_samples = 0
        for i, user in enumerate(users, 1):
            sample_count = self.recognizer.get_user_count(user)
            total_samples += sample_count

            # æ ¹æ®æ ·æœ¬æ•°æ˜¾ç¤ºçŠ¶æ€
            if sample_count >= MIN_ENROLLMENT_SAMPLES:
                status = "âœ…"
            elif sample_count > 0:
                status = "âš ï¸ "
            else:
                status = "âŒ"

            print(f"  {i}. {user} ({count}ä¸ªæ ·æœ¬)")
        print("="*50)
        print(f"ğŸ“Š æ€»æ ·æœ¬æ•°: {total_samples}")
        print(f"ğŸ“ˆ å¹³å‡æ ·æœ¬æ•°: {total_samples/len(users):.1f}")
        input("\næŒ‰å›è½¦é”®è¿”å›...")

    def test_recognition(self):
        """æµ‹è¯•å£°çº¹è¯†åˆ«"""
        users = self.recognizer.get_user_list()

        if not users:
            print("\nâŒ æ²¡æœ‰æ³¨å†Œç”¨æˆ·ï¼Œæ— æ³•æµ‹è¯•")
            input("æŒ‰å›è½¦é”®è¿”å›...")
            return

        print(f"\nğŸ§ª å£°çº¹è¯†åˆ«æµ‹è¯• (å·²æ³¨å†Œç”¨æˆ·: {len(users)}ä¸ª)")
        print("è¯·é€‰æ‹©æµ‹è¯•æ¨¡å¼:")
        print("1. ğŸ¤ å®æ—¶å½•éŸ³æµ‹è¯•")
        print("2. ğŸ“ æ–‡ä»¶æµ‹è¯•ï¼ˆæš‚æœªå®ç°ï¼‰")

        choice = input("è¯·é€‰æ‹© (1-2): ").strip()

        if choice == '1':
            self.real_time_recognition_test()
        else:
            print("æš‚æœªå®ç°")
            input("æŒ‰å›è½¦é”®è¿”å›...")

    def real_time_recognition_test(self):
        """å®æ—¶è¯†åˆ«æµ‹è¯•"""
        print("\nğŸ¤ å®æ—¶å£°çº¹è¯†åˆ«æµ‹è¯•")
        print("æŒ‰è¯´æ˜è¿›è¡Œæ“ä½œ...")

        # è¿™é‡Œå¯ä»¥å®ç°å®æ—¶æµ‹è¯•é€»è¾‘
        # æš‚æ—¶ä½¿ç”¨ç®€åŒ–çš„æµ‹è¯•

        audio_data, quality_info = self.record_audio_with_quality_check(duration=3.0)

        if audio_data is None:
            print("âŒ å½•éŸ³å¤±è´¥")
            return

        # è¿›è¡Œè¯†åˆ«
        user_id = self.recognizer.identify(audio_data)

        if user_id != "unknown":
            print(f"âœ… è¯†åˆ«ç»“æœ: {user_id}")
        else:
            print("âŒ æœªè¯†åˆ«åˆ°å·²çŸ¥ç”¨æˆ·")

        input("\næŒ‰å›è½¦é”®è¿”å›...")

    def user_management(self):
        """ç”¨æˆ·ç®¡ç†"""
        while True:
            print("\nâš™ï¸ ç”¨æˆ·ç®¡ç†")
            print("-"*30)
            users = self.recognizer.get_user_list()

            if users:
                print("å·²æ³¨å†Œç”¨æˆ·:")
                for i, user in enumerate(users, 1):
                    count = self.recognizer.get_user_count(user)
                    print(f"  {i}. {user} ({count}ä¸ªæ ·æœ¬)")
            else:
                print("æš‚æ— æ³¨å†Œç”¨æˆ·")

            print("\næ“ä½œé€‰é¡¹:")
            print("1. ğŸ—‘ï¸ åˆ é™¤ç”¨æˆ·")
            print("2. ğŸ“Š æŸ¥çœ‹ç”¨æˆ·è¯¦æƒ…")
            print("3. ğŸ”„ é‡æ–°æ³¨å†Œç”¨æˆ·")
            print("4. â†©ï¸ è¿”å›ä¸»èœå•")

            choice = input("è¯·é€‰æ‹© (1-4): ").strip()

            if choice == '1' and users:
                self.delete_user(users)
            elif choice == '2' and users:
                self.show_user_details(users)
            elif choice == '3':
                self.interactive_registration()
            elif choice == '4':
                break
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©")

    def delete_user(self, users):
        """åˆ é™¤ç”¨æˆ·"""
        try:
            idx = int(input("è¾“å…¥è¦åˆ é™¤çš„ç”¨æˆ·ç¼–å·: ")) - 1
            if 0 <= idx < len(users):
                user_id = users[idx]
                confirm = input(f"ç¡®è®¤åˆ é™¤ç”¨æˆ· '{user_id}' å—ï¼Ÿ(y/n): ").strip().lower()
                if confirm == 'y':
                    if self.recognizer.remove_user(user_id):
                        print(f"âœ… ç”¨æˆ· '{user_id}' å·²åˆ é™¤")
                    else:
                        print("âŒ åˆ é™¤å¤±è´¥")
            else:
                print("âŒ æ— æ•ˆç”¨æˆ·ç¼–å·")
        except ValueError:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")

    def show_user_details(self, users):
        """æ˜¾ç¤ºç”¨æˆ·è¯¦æƒ…"""
        try:
            idx = int(input("è¾“å…¥è¦æŸ¥çœ‹çš„ç”¨æˆ·ç¼–å·: ")) - 1
            if 0 <= idx < len(users):
                user_id = users[idx]
                count = self.recognizer.get_user_count(user_id)
                print(f"\nğŸ‘¤ ç”¨æˆ·è¯¦æƒ…: {user_id}")
                print(f"ğŸ“Š æ ·æœ¬æ•°é‡: {count}")
                print(f"ğŸ“ˆ æ³¨å†ŒçŠ¶æ€: {'âœ… å®Œæ•´' if count >= MIN_ENROLLMENT_SAMPLES else 'âš ï¸ ä¸å®Œæ•´'}")
            else:
                print("âŒ æ— æ•ˆç”¨æˆ·ç¼–å·")
        except ValueError:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")

        input("\næŒ‰å›è½¦é”®è¿”å›...")

    def quit(self):
        """é€€å‡ºç¨‹åº"""
        print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨æ™ºèƒ½å£°çº¹æ³¨å†Œå·¥å…·ï¼")
        print("ğŸ¤ å†è§ï¼")


def main():
    """ä¸»å‡½æ•°"""
    try:
        tool = SmartSpeakerRegistrationTool()
        tool.run()
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œå†è§ï¼")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå¼‚å¸¸é€€å‡º: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
