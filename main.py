# main.py
import multiprocessing
import time
import sys
import threading
import queue  # å¯¼å…¥ queue æ¨¡å—ç”¨äºå¤„ç† Empty å¼‚å¸¸

from config import SystemState
from tts import TTSEngine

# å¯¼å…¥åŠŸèƒ½æ¨¡å— (Emotion æ¨¡å—æ”¹ä¸ºåœ¨ç±»ä¸­æ‡’åŠ è½½)
from hardware import LEDController, AudioDevice
from asr import ASREngine
from llm import LLMEngine

class VoiceAssistant:
    def __init__(self, mock_mode: bool = False):
        self.mock_mode = mock_mode
        self.state = SystemState.INITIALIZING

        # ç¡¬ä»¶åé¦ˆ
        self.led = LEDController(mock=mock_mode)

        # -----------------------------------------------------------
        # 1. åˆå§‹åŒ–æƒ…æ„Ÿè¯†åˆ«å¼•æ“
        #    (æ”¹ä¸ºåœ¨æ–¹æ³•å†…éƒ¨å¯¼å…¥ï¼Œé˜²æ­¢å­è¿›ç¨‹å¯åŠ¨æ—¶é‡å¤åŠ è½½å¯¼è‡´å´©æºƒ)
        # -----------------------------------------------------------
        print("[System] æ­£åœ¨åŠ è½½æƒ…æ„Ÿè¯†åˆ«æ¨¡å—...")
        try:
            from emotion import EmotionRecognizer  # <--- å…³é”®ä¿®æ”¹ï¼šæ‡’åŠ è½½
            self.emotion_engine = EmotionRecognizer()
            self.current_emotion = "neutral"  # é»˜è®¤æƒ…æ„Ÿ
        except Exception as e:
            print(f"[Error] æƒ…æ„Ÿæ¨¡å—åŠ è½½å¤±è´¥: {e}")
            self.emotion_engine = None
            self.current_emotion = "neutral"

        # -----------------------------------------------------------
        # 2. åˆå§‹åŒ–è¯­éŸ³å¢å¼ºå™¨
        # -----------------------------------------------------------
        print("[System] æ­£åœ¨åŠ è½½è¯­éŸ³å¢å¼ºæ¨¡å—...")
        try:
            from enhancement import AudioEnhancer
            self.audio_enhancer = AudioEnhancer()
        except Exception as e:
            print(f"[Error] è¯­éŸ³å¢å¼ºæ¨¡å—åŠ è½½å¤±è´¥: {e}")
            self.audio_enhancer = None

        # -----------------------------------------------------------
        # 3. åˆå§‹åŒ–å£°çº¹è¯†åˆ«å™¨
        # -----------------------------------------------------------
        print("[System] æ­£åœ¨åŠ è½½å£°çº¹è¯†åˆ«æ¨¡å—...")
        try:
            from speaker import ECAPATDNNRecognizer
            self.speaker_recognizer = ECAPATDNNRecognizer()
            self.current_speaker = "unknown"
        except Exception as e:
            print(f"[Error] å£°çº¹è¯†åˆ«æ¨¡å—åŠ è½½å¤±è´¥: {e}")
            self.speaker_recognizer = None
            self.current_speaker = "unknown"

        # -----------------------------------------------------------
        # 2. å®šä¹‰é˜Ÿåˆ—
        # -----------------------------------------------------------
        self.q_audio = multiprocessing.Queue(maxsize=2000)      # Mic -> ASR (åŸå§‹PCM)
        
        # å°† ASR å’Œ LLM çš„è¿æ¥æ–­å¼€ï¼Œä¸­é—´ç”±ä¸»çº¿ç¨‹ä¸­è½¬
        self.q_asr_output = multiprocessing.Queue()             # ASR -> Main (è¯†åˆ«ç»“æœ)
        self.q_llm_input = multiprocessing.Queue()              # Main -> LLM (æ–‡æœ¬+æƒ…æ„Ÿ)
        
        self.q_asr_cmd = multiprocessing.Queue()                # Main -> ASR (æ§åˆ¶æŒ‡ä»¤)
        self.q_tts_text = multiprocessing.Queue()               # LLM -> TTS (æµå¼æ–‡æœ¬)
        self.q_event = multiprocessing.Queue()                  # TTS -> Main (æ’­æ”¾ç»“æŸäº‹ä»¶)
        self.q_cmd_input = multiprocessing.Queue()              # Keyboard -> Main

        # -----------------------------------------------------------
        # 4. å¯åŠ¨å­è¿›ç¨‹
        # -----------------------------------------------------------
        # ASR è¿›ç¨‹ï¼šè¾“å‡ºåˆ° q_asr_outputï¼Œä¼ å…¥è¯­éŸ³å¢å¼ºå™¨å’Œå£°çº¹è¯†åˆ«å™¨
        self.p_asr = ASREngine(self.q_audio, self.q_asr_output, self.q_asr_cmd, mock=mock_mode, enhancer=self.audio_enhancer, speaker_recognizer=self.speaker_recognizer)
        
        # LLM è¿›ç¨‹ï¼šè¾“å…¥æ”¹ä¸º q_llm_input
        self.p_llm = LLMEngine(self.q_llm_input, self.q_tts_text, mock=mock_mode)
        
        self.p_tts = TTSEngine(self.q_tts_text, self.q_event, audio_device_mock=mock_mode)

        self.is_recording = False
        
        # éŸ³é¢‘ç¼“å†²åŒº (ç”¨äºæƒ…æ„Ÿåˆ†æ)
        self.audio_buffer = bytearray()
        
        # é˜Ÿåˆ—æº¢å‡ºè®¡æ•°å™¨ï¼ˆé¿å…æ—¥å¿—åˆ·å±ï¼‰
        self._queue_overflow_count = 0

    def start(self):
        print("=" * 50)
        print("  è¯­éŸ³äº¤äº’ç³»ç»Ÿ (å«æƒ…æ„Ÿè¯†åˆ«+å£°çº¹è¯†åˆ«) å¯åŠ¨")
        print("  [å›è½¦é”®]    åˆ‡æ¢ å½•éŸ³ / åœæ­¢å¹¶å‘é€")
        print("  [register]  å¯åŠ¨é›†æˆå£°çº¹æ³¨å†Œ (ä½¿ç”¨ä¸»ç³»ç»ŸéŸ³é¢‘è®¾å¤‡)")
        print("  [users]     æŸ¥çœ‹å·²æ³¨å†Œç”¨æˆ·")
        print("  [q] + å›è½¦  é€€å‡ºç¨‹åº")
        print("=" * 50)

        self.p_asr.start()
        self.p_llm.start()
        self.p_tts.start()

        self.input_thread = threading.Thread(target=self.console_listener, daemon=True)
        self.input_thread.start()

        self.switch_state(SystemState.IDLE)
        self.run_loop()

    def console_listener(self):
        """åå°çº¿ç¨‹ç›‘å¬é”®ç›˜è¾“å…¥"""
        while True:
            try:
                cmd = input()
                self.q_cmd_input.put(cmd.strip().lower())
            except EOFError:
                break

    def run_loop(self):
        audio_dev = AudioDevice(mock=self.mock_mode)
        audio_dev.start_stream()
        print("\n[System] å°±ç»ªã€‚æŒ‰å›è½¦å¼€å§‹å¯¹è¯...")

        try:
            while True:
                # ==========================
                # 1. å¤„ç†é”®ç›˜äº¤äº’
                # ==========================
                if not self.q_cmd_input.empty():
                    cmd = self.q_cmd_input.get()

                    if cmd == "q":
                        self.shutdown()
                    elif cmd == "register":
                        self.start_speaker_registration(audio_dev)
                    elif cmd == "users":
                        self.show_registered_users()
                    else:
                        if self.is_recording:
                            # -------- åœæ­¢å½•éŸ³ --------
                            print("\nâœ… å½•éŸ³ç»“æŸï¼Œæ­£åœ¨åˆ†æ...", end="")
                            self.is_recording = False
                            self.switch_state(SystemState.THINKING)
                            
                            # A. æ‰§è¡Œæƒ…æ„Ÿåˆ†æ (ä½¿ç”¨ buffer ä¸­çš„æ•°æ®)
                            if self.emotion_engine and len(self.audio_buffer) > 0:
                                try:
                                    # æ³¨æ„ï¼šemotion_engine.analyze éœ€è¦ bytes ç±»å‹
                                    emo_label = self.emotion_engine.analyze(bytes(self.audio_buffer))
                                    self.current_emotion = emo_label
                                    print(f" [æ£€æµ‹æƒ…æ„Ÿ: {emo_label}]")
                                except Exception as e:
                                    print(f" [æƒ…æ„Ÿåˆ†æå‡ºé”™: {e}]")
                                    self.current_emotion = "neutral"
                            else:
                                self.current_emotion = "neutral"
                            
                            # æ¸…ç©ºéŸ³é¢‘ç¼“å†²ï¼Œå‡†å¤‡ä¸‹ä¸€æ¬¡
                            self.audio_buffer.clear()

                            # B. é€šçŸ¥ ASR æäº¤è¯†åˆ«
                            self.q_asr_cmd.put("COMMIT")

                        else:
                            # -------- å¼€å§‹å½•éŸ³ --------
                            print("\nğŸ”´ æ­£åœ¨å½•éŸ³... (è¯´å®ŒæŒ‰å›è½¦)", end="", flush=True)
                            self.is_recording = True
                            self.switch_state(SystemState.LISTENING)
                            self.audio_buffer.clear() # ç¡®ä¿ç¼“å†²å¹²å‡€
                            self.q_asr_cmd.put("RESET")

                # ==========================
                # 2. è¯»å–éŸ³é¢‘ç¡¬ä»¶æµ
                # ==========================
                pcm = audio_dev.read_chunk()

                if self.is_recording:
                    # åˆ†å‘éŸ³é¢‘æ•°æ®
                    # 1. ç»™ ASR (ç”¨äºè½¬æ–‡å­—)
                    if not self.q_audio.full():
                        self.q_audio.put(pcm)
                        self._queue_overflow_count = 0  # é‡ç½®è®¡æ•°å™¨
                    else:
                        self._queue_overflow_count += 1
                        # æ¯100æ¬¡æº¢å‡ºåªæç¤ºä¸€æ¬¡ï¼Œé¿å…åˆ·å±
                        if self._queue_overflow_count % 100 == 1:
                            print(f"[Warning] éŸ³é¢‘é˜Ÿåˆ—å·²æ»¡ï¼Œä¸¢å¼ƒæ•°æ® ({self._queue_overflow_count}å¸§)")
                    
                    # 2. ç»™ Emotion (å­˜å…¥ç¼“å†²)
                    self.audio_buffer.extend(pcm)

                # ==========================
                # 3. å¤„ç† ASR è¯†åˆ«ç»“æœå¹¶è½¬å‘ç»™ LLM
                # ==========================
                try:
                    # æ£€æŸ¥æ˜¯å¦æœ‰ ASR ç»“æœè¾“å‡º
                    while not self.q_asr_output.empty():
                        asr_data = self.q_asr_output.get_nowait()
                        
                        # å…¼å®¹å¤„ç†ï¼šasr_data å¯èƒ½æ˜¯çº¯æ–‡æœ¬å­—ç¬¦ä¸²ï¼Œä¹Ÿå¯èƒ½æ˜¯å­—å…¸
                        text = ""
                        emotion = "neutral"
                        speaker = "unknown"

                        if isinstance(asr_data, dict):
                            text = asr_data.get("text", "")
                            emotion = asr_data.get("emotion", "neutral")
                            speaker = asr_data.get("speaker", "unknown")
                        elif isinstance(asr_data, str):
                            text = asr_data

                        if text:
                            print(f"[Main] è¯†åˆ«æ–‡æœ¬: {text}")
                            if speaker != "unknown":
                                print(f"[Main] è¯´è¯äºº: {speaker}")

                            # --- å…³é”®æ­¥éª¤ï¼šæ‰“åŒ… æ–‡æœ¬ + æƒ…æ„Ÿ + å£°çº¹ å‘ç»™ LLM ---
                            packet = {
                                "text": text,
                                "emotion": emotion,
                                "speaker": speaker
                            }
                            self.q_llm_input.put(packet)

                            # æ›´æ–°å½“å‰çŠ¶æ€
                            self.current_emotion = "neutral"
                            self.current_speaker = "unknown"

                except queue.Empty:
                    pass

                # ==========================
                # 4. çŠ¶æ€æµè½¬ (THINKING -> SPEAKING)
                # ==========================
                if not self.q_tts_text.empty() and self.state == SystemState.THINKING:
                    self.switch_state(SystemState.SPEAKING)

                # ==========================
                # 5. ç›‘å¬ TTS æ’­æ”¾ç»“æŸ
                # ==========================
                while not self.q_event.empty():
                    evt = self.q_event.get()
                    if evt == "TTS_FINISHED" and not self.is_recording:
                        self.switch_state(SystemState.IDLE)
                        print("\n[System] å›å¤å®Œæ¯•ã€‚æŒ‰å›è½¦ç»§ç»­...")

                time.sleep(0.002)

        except KeyboardInterrupt:
            self.shutdown()

    def switch_state(self, s: SystemState):
        self.state = s
        self.led.set_state(s)

    def start_speaker_registration(self, audio_device):
        """å¯åŠ¨å£°çº¹æ³¨å†Œæµç¨‹ï¼ˆé›†æˆåˆ°ä¸»ç³»ç»Ÿï¼‰"""
        print("\nğŸ¤ å¯åŠ¨å£°çº¹æ³¨å†Œæ¨¡å¼...")
        print("ç°åœ¨æ‚¨å¯ä»¥ä½¿ç”¨ä¸»ç³»ç»Ÿçš„éº¦å…‹é£å’ŒASRå¼•æ“è¿›è¡Œæ³¨å†Œ")

        try:
            # åˆ›å»ºé›†æˆæ³¨å†Œç®¡ç†å™¨
            from integrated_registration import IntegratedRegistrationManager
            registration_manager = IntegratedRegistrationManager(
                audio_device=audio_device,
                speaker_recognizer=self.speaker_recognizer,
                audio_enhancer=self.audio_enhancer,
                asr_queue=self.q_audio,  # ASRéŸ³é¢‘é˜Ÿåˆ—
                text_queue=self.q_asr_output  # ASRæ–‡æœ¬é˜Ÿåˆ—
            )

            # è¿è¡Œé›†æˆæ³¨å†Œ
            registration_manager.run_registration()

            print("\nâœ… è¿”å›è¯­éŸ³åŠ©æ‰‹ä¸»ç•Œé¢")
            print("æŒ‰å›è½¦é”®ç»§ç»­å¯¹è¯...")

        except Exception as e:
            print(f"âŒ å¯åŠ¨æ³¨å†Œæ¨¡å¼å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            print("å›é€€åˆ°ç‹¬ç«‹æ³¨å†Œå·¥å…·...")
            try:
                from register_speaker import SpeakerRegistrationTool
                tool = SpeakerRegistrationTool()
                tool.run()
            except Exception as e2:
                print(f"âŒ ç‹¬ç«‹æ³¨å†Œå·¥å…·ä¹Ÿå¤±è´¥: {e2}")
                print("è¯·æ£€æŸ¥ç³»ç»Ÿé…ç½®")

    def show_registered_users(self):
        """æ˜¾ç¤ºå·²æ³¨å†Œç”¨æˆ·"""
        try:
            users = self.speaker_recognizer.get_user_list()
            if users:
                print(f"\nğŸ‘¥ å·²æ³¨å†Œç”¨æˆ· ({len(users)} ä¸ª):")
                for user in users:
                    count = self.speaker_recognizer.get_user_count(user)
                    status = "âœ…" if count >= 3 else "âš ï¸ "
                    print(f"  {status} {user}: {count} ä¸ªæ ·æœ¬")
            else:
                print("\nğŸ“­ æš‚æ— æ³¨å†Œç”¨æˆ·")
                print("è¾“å…¥ 'register' å¼€å§‹æ³¨å†Œå£°çº¹")
        except Exception as e:
            print(f"âŒ è·å–ç”¨æˆ·åˆ—è¡¨å¤±è´¥: {e}")

    def shutdown(self):
        print("\næ­£åœ¨é€€å‡º...")
        self.p_asr.terminate()
        self.p_llm.terminate()
        self.p_tts.terminate()
        sys.exit(0)


if __name__ == "__main__":
    # Windowsä¸‹å¤šè¿›ç¨‹å¿…é¡»æ”¾åœ¨ if __name__ == "__main__": ä¹‹ä¸‹
    app = VoiceAssistant(mock_mode=False) 
    app.start()