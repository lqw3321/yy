#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å£°çº¹æ³¨å†Œå·¥å…· v4.0
æ™ºèƒ½å£°çº¹æ³¨å†Œç³»ç»Ÿ
æ”¯æŒéŸ³é¢‘è´¨é‡ç›‘æ§ã€å®æ—¶åé¦ˆã€å¤šé‡éªŒè¯
"""

import os
import sys
import time
import tempfile
import numpy as np
import soundfile as sf
from typing import List, Optional, Tuple, Dict
import threading
import queue

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

from speaker import ECAPATDNNRecognizer
from config import SAMPLE_RATE, MIN_ENROLLMENT_SAMPLES, MIC_DEVICE_INDEX, SPEAKER_SIMILARITY_THRESHOLD
from enhancement import AudioEnhancer


class AudioQualityAnalyzer:
    """éŸ³é¢‘è´¨é‡åˆ†æå™¨"""

    def __init__(self):
        self.quality_thresholds = {
            'min_rms': 0.08,      # æœ€å°æœ‰æ•ˆRMS
            'max_rms': 0.7,       # æœ€å¤§RMSï¼ˆé¿å…è¿‡è½½ï¼‰
            'min_length': 1.5,    # æœ€çŸ­éŸ³é¢‘é•¿åº¦
            'max_silence': 0.2,   # æœ€å¤§é™éŸ³æ¯”ä¾‹
        }

    def analyze_audio(self, audio_data: bytes) -> Dict:
        """åˆ†æéŸ³é¢‘è´¨é‡"""
        try:
            audio_np = np.frombuffer(audio_data, dtype=np.int16).astype(np.float32) / 32768.0
            length = len(audio_np) / SAMPLE_RATE

            # åŸºæœ¬ç»Ÿè®¡
            rms = np.sqrt(np.mean(audio_np**2))
            peak = np.max(np.abs(audio_np))
            silence_frames = np.sum(np.abs(audio_np) < 0.01)
            silence_ratio = silence_frames / len(audio_np)

            # è´¨é‡è¯„åˆ†
            quality_score = self._calculate_quality_score(rms, length, silence_ratio)

            return {
                'rms': rms,
                'peak': peak,
                'length': length,
                'silence_ratio': silence_ratio,
                'quality_score': quality_score,
                'is_acceptable': quality_score >= 0.6,
                'feedback': self._get_feedback(rms, length, silence_ratio, quality_score)
            }
        except Exception as e:
            return {
                'error': str(e),
                'is_acceptable': False,
                'feedback': f"éŸ³é¢‘åˆ†æå¤±è´¥: {e}"
            }

    def _calculate_quality_score(self, rms: float, length: float, silence_ratio: float) -> float:
        """è®¡ç®—è´¨é‡åˆ†æ•° (0-1)"""
        score = 0.0

        # RMSè¯„åˆ† (40%)
        if rms < self.quality_thresholds['min_rms']:
            rms_score = rms / self.quality_thresholds['min_rms'] * 0.5
        elif rms > self.quality_thresholds['max_rms']:
            rms_score = 0.5
        else:
            # æœ€ä½³èŒƒå›´ 0.15-0.4
            if 0.15 <= rms <= 0.4:
                rms_score = 1.0
            else:
                rms_score = 0.8

        # é•¿åº¦è¯„åˆ† (30%)
        if length < self.quality_thresholds['min_length']:
            length_score = length / self.quality_thresholds['min_length']
        else:
            length_score = min(length / 3.0, 1.0)

        # é™éŸ³è¯„åˆ† (30%)
        silence_score = 1.0 - min(silence_ratio / self.quality_thresholds['max_silence'], 1.0)

        score = 0.4 * rms_score + 0.3 * length_score + 0.3 * silence_score
        return min(max(score, 0.0), 1.0)

    def _get_feedback(self, rms: float, length: float, silence_ratio: float, score: float) -> str:
        """ç”Ÿæˆè´¨é‡åé¦ˆ"""
        feedback = []

        if score >= 0.8:
            feedback.append("âœ… éŸ³é¢‘è´¨é‡ä¼˜ç§€ï¼")
        elif score >= 0.6:
            feedback.append("ğŸ‘ éŸ³é¢‘è´¨é‡è‰¯å¥½")
        else:
            feedback.append("âš ï¸ éŸ³é¢‘è´¨é‡éœ€è¦æ”¹è¿›")

        # å…·ä½“å»ºè®®
        if rms < self.quality_thresholds['min_rms']:
            feedback.append(".3f"        elif rms > self.quality_thresholds['max_rms']:
            feedback.append(".3f"        if length < self.quality_thresholds['min_length']:
            feedback.append(".1f"        if silence_ratio > self.quality_thresholds['max_silence']:
            feedback.append(".1%")

        return " | ".join(feedback)


class SmartSpeakerRegistrationTool:
    """æ™ºèƒ½å£°çº¹æ³¨å†Œå·¥å…· v4.0"""

    def __init__(self):
        self.recognizer = ECAPATDNNRecognizer()
        self.quality_analyzer = AudioQualityAnalyzer()
        self.enhancer = AudioEnhancer()

        # æ³¨å†Œä¼šè¯çŠ¶æ€
        self.session_stats = {
            'user_id': None,
            'attempts': 0,
            'successful_samples': 0,
            'quality_scores': [],
            'best_quality': 0.0
        }

        print("ğŸ¤ æ™ºèƒ½å£°çº¹æ³¨å†Œå·¥å…· v4.0 åˆå§‹åŒ–å®Œæˆ")
        print("âœ¨ æ”¯æŒå®æ—¶è´¨é‡ç›‘æ§å’Œæ™ºèƒ½å¼•å¯¼")

    def record_audio_with_quality_check(self, duration: float = 3.0, show_feedback: bool = True) -> Tuple[Optional[bytes], Dict]:
        """æ™ºèƒ½å½•éŸ³å‡½æ•°ï¼ŒåŒ…å«è´¨é‡åˆ†æ"""
        try:
            import pyaudio

            chunk = 1024
            format = pyaudio.paInt16
            channels = 1
            rate = SAMPLE_RATE

            p = pyaudio.PyAudio()

            # éªŒè¯è®¾å¤‡
            try:
                device_info = p.get_device_info_by_host_api_device_index(0, MIC_DEVICE_INDEX)
                if device_info.get('maxInputChannels') <= 0:
                    return None, {'error': f'è®¾å¤‡ {MIC_DEVICE_INDEX} æ²¡æœ‰è¾“å…¥é€šé“'}
                if show_feedback:
                    print(f"ğŸ¤ ä½¿ç”¨è®¾å¤‡: {device_info['name']} (ç´¢å¼•: {MIC_DEVICE_INDEX})")
            except Exception as e:
                return None, {'error': f'æ— æ³•è®¿é—®è®¾å¤‡ {MIC_DEVICE_INDEX}: {e}'}

            # æ‰“å¼€éŸ³é¢‘æµ
            stream = p.open(
                format=format,
                channels=channels,
                rate=rate,
                input=True,
                input_device_index=MIC_DEVICE_INDEX,
                frames_per_buffer=chunk
            )

            # æ˜¾ç¤ºä½¿ç”¨çš„è®¾å¤‡
            try:
                device_info = p.get_device_info_by_host_api_device_index(0, MIC_DEVICE_INDEX)
                print(f"ğŸ¤ ä½¿ç”¨è®¾å¤‡: {device_info['name']} (ç´¢å¼•: {MIC_DEVICE_INDEX})")
            except Exception as e:
                print(f"âš ï¸ æ— æ³•è·å–è®¾å¤‡ä¿¡æ¯: {e}")

            stream = p.open(
                format=format,
                channels=channels,
                rate=SAMPLE_RATE,
                input=True,
                input_device_index=MIC_DEVICE_INDEX,
                frames_per_buffer=chunk
            )

            print(f"ğŸ™ï¸ å¼€å§‹å½•éŸ³ {duration} ç§’...")
            print("è¯·æ¸…æ™°åœ°è¯´å‡ºå¥å­ï¼Œä¿æŒè‡ªç„¶è¯­é€Ÿ")
            print("ğŸ’¡ æç¤ºï¼šä¿æŒ15-30cmè·ç¦»ï¼ŒéŸ³é‡é€‚ä¸­")

            frames = []

            # æ˜¾ç¤ºè¿›åº¦æ¡
            total_chunks = int(duration * SAMPLE_RATE / chunk)
            for i in range(total_chunks):
                data = stream.read(chunk)
                frames.append(data)

                # æ¯0.5ç§’æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
                if i % int(0.5 * SAMPLE_RATE / chunk) == 0:
                    progress = (i + 1) / total_chunks
                    bar_length = 20
                    filled = int(bar_length * progress)
                    bar = "â–ˆ" * filled + "â–‘" * (bar_length - filled)
                    print(f"\râ±ï¸ å½•éŸ³è¿›åº¦: [{bar}] {progress:.1%}", end="", flush=True)

            print(" âœ…")  # å®Œæˆè¿›åº¦æ¡

            stream.stop_stream()
            stream.close()
            p.terminate()

            # åˆå¹¶éŸ³é¢‘æ•°æ®
            audio_data = b''.join(frames)

            # åˆ†æéŸ³é¢‘è´¨é‡
            quality_info = self.quality_analyzer.analyze_audio(audio_data)

            return audio_data, quality_info

        except Exception as e:
            print(f"âŒ å½•éŸ³å¤±è´¥: {e}")
            return None

    def _analyze_audio(self, audio_data: bytes) -> dict:
        """åˆ†æéŸ³é¢‘è´¨é‡"""
        try:
            audio_np = np.frombuffer(audio_data, dtype=np.int16).astype(np.float32) / 32768.0
            length = len(audio_np) / SAMPLE_RATE
            rms = np.sqrt(np.mean(audio_np**2))

            if length < 1.0:
                return {'valid': False, 'reason': 'éŸ³é¢‘å¤ªçŸ­'}
            if rms < 0.01:
                return {'valid': False, 'reason': 'éŸ³é¢‘ä¿¡å·å¤ªå¼±', 'rms': rms}

            return {
                'valid': True,
                'length': length,
                'rms': rms,
                'quality': 'è‰¯å¥½' if rms > 0.1 else 'ä¸€èˆ¬'
            }
        except Exception as e:
            return {'valid': False, 'reason': f'åˆ†æé”™è¯¯: {e}'}

    def register_user_interactive(self):
        """äº¤äº’å¼æ³¨å†Œç”¨æˆ·"""
        print("\n" + "="*50)
        print("ğŸ¤ å£°çº¹æ³¨å†Œç³»ç»Ÿ v3.0")
        print("="*50)

        # è¾“å…¥ç”¨æˆ·å
        while True:
            user_id = input("\nè¯·è¾“å…¥ç”¨æˆ·åï¼ˆå­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿ï¼‰ï¼š").strip()
            if not user_id:
                print("âŒ ç”¨æˆ·åä¸èƒ½ä¸ºç©º")
                continue

            if not all(c.isalnum() or c == '_' for c in user_id):
                print("âŒ ç”¨æˆ·ååªèƒ½åŒ…å«å­—æ¯ã€æ•°å­—å’Œä¸‹åˆ’çº¿")
                continue

            break

        # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å·²å­˜åœ¨
        existing_users = self.recognizer.get_user_list()
        if user_id in existing_users:
            count = self.recognizer.get_user_count(user_id)
            print(f"â„¹ï¸  ç”¨æˆ· '{user_id}' å·²å­˜åœ¨ï¼Œå½“å‰æœ‰ {count} ä¸ªæ ·æœ¬")

            choice = input("æ˜¯å¦ç»§ç»­æ·»åŠ æ–°æ ·æœ¬ï¼Ÿ(y/n): ").strip().lower()
            if choice != 'y':
                print("æ³¨å†Œå–æ¶ˆ")
                return

        # å¼€å§‹æ³¨å†Œæµç¨‹
        print(f"\nğŸ¯ å¼€å§‹ä¸ºç”¨æˆ· '{user_id}' æ³¨å†Œå£°çº¹")
        print(f"éœ€è¦å½•åˆ¶ {MIN_ENROLLMENT_SAMPLES} ä¸ªè¯­éŸ³æ ·æœ¬")

        sample_sentences = [
            "ä»Šå¤©å¤©æ°”çœŸä¸é”™",
            "æˆ‘å–œæ¬¢å¬éŸ³ä¹",
            "è°¢è°¢ä½ çš„å¸®åŠ©",
            "äººå·¥æ™ºèƒ½å‘å±•å¾ˆå¿«",
            "è¯­éŸ³è¯†åˆ«æŠ€æœ¯å¾ˆæœ‰è¶£"
        ]

        collected_samples = 0
        while collected_samples < MIN_ENROLLMENT_SAMPLES:
            print(f"\nğŸ“ å½•åˆ¶ç¬¬ {collected_samples + 1}/{MIN_ENROLLMENT_SAMPLES} ä¸ªæ ·æœ¬")

            # æ˜¾ç¤ºå»ºè®®å¥å­
            if collected_samples < len(sample_sentences):
                print(f"å»ºè®®å¥å­ï¼š'{sample_sentences[collected_samples]}'")
            else:
                print("è¯·è¯´ä»»æ„ä¸€å¥è‡ªç„¶çš„è¯")

            # å½•éŸ³
            audio_data = self._record_audio(duration=3.0)
            if audio_data is None:
                continue

            # åˆ†æéŸ³é¢‘è´¨é‡
            analysis = self._analyze_audio(audio_data)
            if not analysis['valid']:
                print(f"âŒ {analysis['reason']}")
                print("è¯·é‡æ–°å½•åˆ¶")
                continue

            print(".2f")
            print(f"éŸ³é¢‘è´¨é‡: {analysis['quality']}")

            # æ³¨å†Œæ ·æœ¬
            success = self.recognizer.enroll_user(user_id, audio_data)
            if success:
                collected_samples += 1
                print(f"âœ… ç¬¬ {collected_samples}/{MIN_ENROLLMENT_SAMPLES} ä¸ªæ ·æœ¬æ³¨å†ŒæˆåŠŸï¼")
            else:
                print("âŒ æ³¨å†Œå¤±è´¥ï¼Œè¯·é‡è¯•")

            if collected_samples < MIN_ENROLLMENT_SAMPLES:
                input("\næŒ‰å›è½¦é”®ç»§ç»­å½•åˆ¶ä¸‹ä¸€ä¸ªæ ·æœ¬...")

        # æ³¨å†Œå®Œæˆ
        print(f"\nğŸ‰ æ³¨å†Œå®Œæˆï¼")
        final_count = self.recognizer.get_user_count(user_id)
        print(f"ğŸ‘¤ ç”¨æˆ·: {user_id}")
        print(f"ğŸ“Š æ³¨å†Œæ ·æœ¬æ•°: {final_count}")

        # æ˜¾ç¤ºæ‰€æœ‰ç”¨æˆ·
        all_users = self.recognizer.get_user_list()
        print(f"\nğŸ‘¥ å·²æ³¨å†Œç”¨æˆ· ({len(all_users)} ä¸ª):")
        for user in all_users:
            count = self.recognizer.get_user_count(user)
            status = "âœ…" if count >= MIN_ENROLLMENT_SAMPLES else "âš ï¸"
            print(f"  {status} {user}: {count} ä¸ªæ ·æœ¬")

    def run(self):
        """è¿è¡Œæ³¨å†Œå·¥å…·"""
        self.register_user_interactive()


def main():
    """ä¸»å‡½æ•°"""
    try:
        tool = SpeakerRegistrationTool()
        tool.run()
    except KeyboardInterrupt:
        print("\nğŸ‘‹ æ³¨å†Œå·²å–æ¶ˆ")
    except Exception as e:
        print(f"âŒ ç¨‹åºå‡ºé”™: {e}")


if __name__ == "__main__":
    main()

    def record_audio(self, duration: float = 3.0) -> Optional[bytes]:
        """ä»éº¦å…‹é£å½•åˆ¶éŸ³é¢‘"""
        try:
            import pyaudio
        except ImportError:
            print("é”™è¯¯ï¼šæœªå®‰è£…pyaudioï¼Œæ— æ³•å½•éŸ³")
            print("è¯·è¿è¡Œï¼špip install pyaudio")
            return None

        chunk = 1024
        format = pyaudio.paInt16
        channels = 1
        sample_rate = SAMPLE_RATE

        p = pyaudio.PyAudio()

        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„è¾“å…¥è®¾å¤‡
            info = p.get_host_api_info_by_index(0)
            device_count = info.get('deviceCount')

            # ä½¿ç”¨ä¸main.pyç›¸åŒçš„è®¾å¤‡ç´¢å¼•
            input_device = MIC_DEVICE_INDEX

            # éªŒè¯è®¾å¤‡æœ‰æ•ˆæ€§
            try:
                device_info = p.get_device_info_by_host_api_device_index(0, input_device)
                print(f"ğŸ¤ ä½¿ç”¨è®¾å¤‡: {device_info['name']} (ç´¢å¼•: {input_device})")

                if device_info.get('maxInputChannels') <= 0:
                    print(f"é”™è¯¯ï¼šè®¾å¤‡ {input_device} æ²¡æœ‰è¾“å…¥é€šé“")
                    print("è¯·æ£€æŸ¥config.pyä¸­çš„MIC_DEVICE_INDEXè®¾ç½®")
                    return None
            except Exception as e:
                print(f"é”™è¯¯ï¼šæ— æ³•è·å–è®¾å¤‡ {input_device} ä¿¡æ¯: {e}")
                print("è¯·æ£€æŸ¥config.pyä¸­çš„MIC_DEVICE_INDEXè®¾ç½®")
                return None

            stream = p.open(format=format,
                          channels=channels,
                          rate=sample_rate,
                          input=True,
                          input_device_index=input_device,
                          frames_per_buffer=chunk)

            print(f"ğŸ¤ å¼€å§‹å½•éŸ³ {duration} ç§’...")
            print("è¯·æ¸…æ™°åœ°è¯´å‡ºå¥å­ï¼Œä¿æŒè‡ªç„¶è¯­é€Ÿ")

            frames = []

            # æ˜¾ç¤ºå€’è®¡æ—¶
            for i in range(int(duration * 10)):
                remaining = duration - (i * 0.1)
                print(f"\râ±ï¸  å‰©ä½™æ—¶é—´: {remaining:.1f}ç§’", end="", flush=True)
                time.sleep(0.1)

                # æ¯0.1ç§’è¯»ä¸€æ¬¡æ•°æ®
                if i % 1 == 0:  # æ¯10æ¬¡å¾ªç¯ï¼ˆ1ç§’ï¼‰æ”¶é›†æ•°æ®
                    data = stream.read(chunk)
                    frames.append(data)

            print("\nâœ… å½•éŸ³å®Œæˆï¼")

            stream.stop_stream()
            stream.close()

            return b''.join(frames)

        except Exception as e:
            print(f"å½•éŸ³å¤±è´¥: {e}")
            return None
        finally:
            p.terminate()

    def generate_test_audio(self, frequency: float = 440.0, duration: float = 3.0) -> bytes:
        """ç”Ÿæˆæµ‹è¯•éŸ³é¢‘ï¼ˆç”¨äºæ¼”ç¤ºï¼‰"""
        sample_rate = SAMPLE_RATE
        t = np.linspace(0, duration, int(sample_rate * duration), False)

        # ç”Ÿæˆç®€å•çš„æ­£å¼¦æ³¢
        audio = 0.5 * np.sin(2 * np.pi * frequency * t)

        # æ·»åŠ ä¸€äº›è°æ³¢ä½¿å£°éŸ³æ›´è‡ªç„¶
        audio += 0.3 * np.sin(2 * np.pi * frequency * 2 * t)
        audio += 0.1 * np.sin(2 * np.pi * frequency * 3 * t)

        # æ·»åŠ è½»å¾®å™ªå£°
        audio += 0.05 * np.random.normal(0, 1, len(audio))

        # è½¬æ¢ä¸º16ä½PCM
        audio_int16 = (audio * 32767).astype(np.int16)
        return audio_int16.tobytes()

    def register_user_interactive(self):
        """äº¤äº’å¼æ³¨å†Œç”¨æˆ·"""
        print("\n" + "="*50)
        print("ğŸ¤ å£°çº¹æ³¨å†Œç³»ç»Ÿ - äº¤äº’å¼æ³¨å†Œ")
        print("="*50)

        # è¾“å…¥ç”¨æˆ·å
        while True:
            user_id = input("\nè¯·è¾“å…¥ç”¨æˆ·åï¼ˆå­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿ï¼‰ï¼š").strip()
            if not user_id:
                print("âŒ ç”¨æˆ·åä¸èƒ½ä¸ºç©º")
                continue

            # æ£€æŸ¥ç”¨æˆ·åæ ¼å¼
            if not all(c.isalnum() or c == '_' for c in user_id):
                print("âŒ ç”¨æˆ·ååªèƒ½åŒ…å«å­—æ¯ã€æ•°å­—å’Œä¸‹åˆ’çº¿")
                continue

            break

        # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å·²å­˜åœ¨
        existing_users = self.recognizer.get_user_list()
        if user_id in existing_users:
            count = self.recognizer.get_user_count(user_id)
            print(f"â„¹ï¸  ç”¨æˆ· '{user_id}' å·²å­˜åœ¨ï¼Œå½“å‰æœ‰ {count} ä¸ªæ ·æœ¬")

            choice = input("æ˜¯å¦ç»§ç»­æ·»åŠ æ–°æ ·æœ¬ï¼Ÿ(y/n): ").strip().lower()
            if choice != 'y':
                print("æ³¨å†Œå–æ¶ˆ")
                return

        # å¼€å§‹æ³¨å†Œæµç¨‹
        print(f"\nğŸ¯ å¼€å§‹ä¸ºç”¨æˆ· '{user_id}' æ³¨å†Œå£°çº¹")
        print("éœ€è¦å½•åˆ¶å¤šä¸ªè¯­éŸ³æ ·æœ¬ä»¥æé«˜è¯†åˆ«å‡†ç¡®ç‡")
        print("å»ºè®®ï¼šæ¯ä¸ªæ ·æœ¬è¯´ä¸åŒçš„å¥å­ï¼Œä¿æŒè‡ªç„¶è¯­é€Ÿ")

        required_samples = MIN_ENROLLMENT_SAMPLES
        collected_samples = 0
        sample_sentences = [
            "ä»Šå¤©å¤©æ°”çœŸä¸é”™",
            "æˆ‘å–œæ¬¢å¬éŸ³ä¹",
            "è°¢è°¢ä½ çš„å¸®åŠ©",
            "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å¥å­",
            "è¯­éŸ³è¯†åˆ«æŠ€æœ¯å¾ˆæœ‰è¶£",
            "äººå·¥æ™ºèƒ½å‘å±•å¾ˆå¿«",
            "è¯·é—®ç°åœ¨å‡ ç‚¹äº†",
            "æˆ‘æƒ³å¬ä¸€é¦–æ­Œ",
            "è¿™ä¸ªåŠŸèƒ½å¾ˆå®ç”¨",
            "å£°çº¹è¯†åˆ«çœŸç¥å¥‡"
        ]

        while collected_samples < required_samples:
            print(f"\n" + "-"*30)
            print(f"ğŸ“ å½•åˆ¶ç¬¬ {collected_samples + 1}/{required_samples} ä¸ªæ ·æœ¬")

            # å»ºè®®å¥å­
            if collected_samples < len(sample_sentences):
                print(f"å»ºè®®å¥å­ï¼š'{sample_sentences[collected_samples]}'")
            else:
                print("è¯·è¯´ä»»æ„ä¸€å¥è‡ªç„¶çš„è¯")

            # è¯¢é—®æ˜¯å¦ä½¿ç”¨çœŸå®å½•éŸ³è¿˜æ˜¯æµ‹è¯•éŸ³é¢‘
            use_real_audio = input("ä½¿ç”¨çœŸå®å½•éŸ³ï¼Ÿ(y=çœŸå®å½•éŸ³, n=æµ‹è¯•éŸ³é¢‘): ").strip().lower()

            if use_real_audio == 'y':
                audio_data = self.record_audio(duration=3.0)
                if audio_data is None:
                    print("âŒ å½•éŸ³å¤±è´¥ï¼Œè·³è¿‡æ­¤æ ·æœ¬")
                    continue
            else:
                # ä½¿ç”¨æµ‹è¯•éŸ³é¢‘
                frequency = 440 + (collected_samples * 50)  # ä¸åŒçš„é¢‘ç‡æ¨¡æ‹Ÿä¸åŒè¯­éŸ³
                audio_data = self.generate_test_audio(frequency=frequency, duration=3.0)
                print("âœ… å·²ç”Ÿæˆæµ‹è¯•éŸ³é¢‘")

            # æ˜¾ç¤ºè¯†åˆ«å†…å®¹
            if use_real_audio == 'y':
                print("ğŸ” æ­£åœ¨åˆ†ææ‚¨åˆšæ‰è¯´çš„å†…å®¹...")
                recognized_text = self.recognize_audio_content(audio_data)
                print(f"ğŸ™ï¸ è¯†åˆ«ç»“æœ: ã€{recognized_text}ã€‘")

                # è¯¢é—®æ˜¯å¦ç¡®è®¤
                confirm = input("å†…å®¹æ˜¯å¦æ­£ç¡®ï¼Ÿ(y=ç¡®è®¤, n=é‡æ–°å½•åˆ¶, s=è·³è¿‡ç¡®è®¤): ").strip().lower()
                if confirm == 'n':
                    print("ğŸ”„ é‡æ–°å½•åˆ¶æ­¤æ ·æœ¬...")
                    continue  # é‡æ–°å½•åˆ¶ï¼Œä¸å¢åŠ collected_samples
                elif confirm == 's':
                    print("â­ï¸ è·³è¿‡ç¡®è®¤ï¼Œç»§ç»­æ³¨å†Œ...")
                # å¦‚æœæ˜¯'y'æˆ–å…¶ä»–ï¼Œç›´æ¥ç»§ç»­

            # æ³¨å†Œæ ·æœ¬
            success = self.recognizer.enroll_user(user_id, audio_data)

            if success:
                collected_samples += 1
                print(f"âœ… ç¬¬ {collected_samples}/{required_samples} ä¸ªæ ·æœ¬æ³¨å†ŒæˆåŠŸï¼")
            else:
                print(f"âŒ ç¬¬ {collected_samples + 1} ä¸ªæ ·æœ¬æ³¨å†Œå¤±è´¥")

            # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªæ ·æœ¬ï¼Œç¨ä½œåœé¡¿
            if collected_samples < required_samples:
                input("\næŒ‰å›è½¦é”®ç»§ç»­å½•åˆ¶ä¸‹ä¸€ä¸ªæ ·æœ¬...")

        # æ³¨å†Œå®Œæˆ
        print(f"\n" + "="*50)
        if collected_samples > 0:
            final_count = self.recognizer.get_user_count(user_id)
            print(f"ğŸ‰ æ³¨å†Œå®Œæˆï¼")
            print(f"ğŸ‘¤ ç”¨æˆ·å: {user_id}")
            print(f"ğŸ“Š æ³¨å†Œæ ·æœ¬æ•°: {final_count}")

            if final_count >= 3:
                print("âœ… æ³¨å†ŒæˆåŠŸï¼ç°åœ¨å¯ä»¥è¿›è¡Œå£°çº¹è¯†åˆ«äº†")
            else:
                print("âš ï¸  å»ºè®®å†æ³¨å†Œä¸€äº›æ ·æœ¬ä»¥æé«˜å‡†ç¡®ç‡")
        else:
            print("âŒ æ³¨å†Œå¤±è´¥ï¼Œæ²¡æœ‰æˆåŠŸæ³¨å†Œä»»ä½•æ ·æœ¬")

        # æ˜¾ç¤ºæ‰€æœ‰ç”¨æˆ·
        self.show_registered_users()

    def register_user_batch(self, user_id: str, audio_files: List[str]):
        """æ‰¹é‡æ³¨å†Œç”¨æˆ·ä»éŸ³é¢‘æ–‡ä»¶"""
        print(f"\nğŸ“ æ‰¹é‡æ³¨å†Œç”¨æˆ· '{user_id}'")
        print(f"ä» {len(audio_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶æ³¨å†Œ")

        success_count = 0

        for i, audio_file in enumerate(audio_files, 1):
            if not os.path.exists(audio_file):
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {audio_file}")
                continue

            try:
                # è¯»å–éŸ³é¢‘æ–‡ä»¶
                import soundfile as sf

                audio_data, sample_rate = sf.read(audio_file, dtype='int16')

                # å¦‚æœæ˜¯ç«‹ä½“å£°ï¼Œè½¬ä¸ºå•å£°é“
                if len(audio_data.shape) > 1:
                    audio_data = audio_data.mean(axis=1).astype(np.int16)

                # è½¬æ¢ä¸ºbytes
                audio_bytes = audio_data.tobytes()

                # æ³¨å†Œ
                success = self.recognizer.enroll_user(user_id, audio_bytes)

                if success:
                    success_count += 1
                    print(f"âœ… æ–‡ä»¶ {i}/{len(audio_files)}: {os.path.basename(audio_file)} æ³¨å†ŒæˆåŠŸ")
                else:
                    print(f"âŒ æ–‡ä»¶ {i}/{len(audio_files)}: {os.path.basename(audio_file)} æ³¨å†Œå¤±è´¥")

            except Exception as e:
                print(f"âŒ å¤„ç†æ–‡ä»¶ {audio_file} æ—¶å‡ºé”™: {e}")

        print(f"\nğŸ“Š æ‰¹é‡æ³¨å†Œå®Œæˆ: {success_count}/{len(audio_files)} ä¸ªæ–‡ä»¶æˆåŠŸ")
        final_count = self.recognizer.get_user_count(user_id)
        print(f"ğŸ‘¤ ç”¨æˆ· '{user_id}' å…±æœ‰ {final_count} ä¸ªæ³¨å†Œæ ·æœ¬")

    def show_registered_users(self):
        """æ˜¾ç¤ºæ‰€æœ‰æ³¨å†Œç”¨æˆ·"""
        users = self.recognizer.get_user_list()

        if not users:
            print("\nğŸ“­ å½“å‰æ²¡æœ‰æ³¨å†Œç”¨æˆ·")
            return

        print(f"\nğŸ‘¥ å·²æ³¨å†Œç”¨æˆ· ({len(users)} ä¸ª):")
        print("-" * 30)

        for user in users:
            count = self.recognizer.get_user_count(user)
            status = "âœ…" if count >= 3 else "âš ï¸ "
            print(f"  {status} {user}: {count} ä¸ªæ ·æœ¬")

    def test_recognition(self):
        """æµ‹è¯•å£°çº¹è¯†åˆ«åŠŸèƒ½"""
        print("\nğŸ§ª å£°çº¹è¯†åˆ«æµ‹è¯•")
        print("-" * 30)

        users = self.recognizer.get_user_list()
        if not users:
            print("âŒ æ²¡æœ‰æ³¨å†Œç”¨æˆ·ï¼Œæ— æ³•æµ‹è¯•è¯†åˆ«")
            return

        print("å·²æ³¨å†Œç”¨æˆ·:", ", ".join(users))

        # ä½¿ç”¨æµ‹è¯•éŸ³é¢‘è¿›è¡Œè¯†åˆ«
        test_frequency = 440.0  # ä½¿ç”¨ç¬¬ä¸€ä¸ªç”¨æˆ·çš„é¢‘ç‡
        test_audio = self.generate_test_audio(frequency=test_frequency, duration=2.0)

        print("ğŸ¤ æ­£åœ¨è¯†åˆ«æµ‹è¯•éŸ³é¢‘...")
        result = self.recognizer.identify(test_audio)

        if result != "unknown":
            print(f"âœ… è¯†åˆ«ç»“æœ: {result}")
        else:
            print("âŒ è¯†åˆ«å¤±è´¥ï¼ŒæœªåŒ¹é…åˆ°å·²çŸ¥ç”¨æˆ·")

    def manage_users(self):
        """ç”¨æˆ·ç®¡ç†"""
        while True:
            print("\nğŸ‘¥ ç”¨æˆ·ç®¡ç†")
            print("-" * 20)
            print("1. æŸ¥çœ‹æ‰€æœ‰ç”¨æˆ·")
            print("2. åˆ é™¤ç”¨æˆ·")
            print("3. æ¸…ç©ºæ‰€æœ‰ç”¨æˆ·")
            print("4. è¿”å›ä¸»èœå•")

            choice = input("\nè¯·é€‰æ‹©æ“ä½œ (1-4): ").strip()

            if choice == "1":
                self.show_registered_users()

            elif choice == "2":
                users = self.recognizer.get_user_list()
                if not users:
                    print("âŒ æ²¡æœ‰æ³¨å†Œç”¨æˆ·")
                    continue

                print("å·²æ³¨å†Œç”¨æˆ·:")
                for i, user in enumerate(users, 1):
                    count = self.recognizer.get_user_count(user)
                    print(f"  {i}. {user} ({count} ä¸ªæ ·æœ¬)")

                try:
                    user_choice = input("è¯·è¾“å…¥è¦åˆ é™¤çš„ç”¨æˆ·ç¼–å·: ").strip()
                    user_index = int(user_choice) - 1

                    if 0 <= user_index < len(users):
                        user_to_delete = users[user_index]
                        confirm = input(f"ç¡®å®šè¦åˆ é™¤ç”¨æˆ· '{user_to_delete}' å—ï¼Ÿ(y/n): ").strip().lower()

                        if confirm == 'y':
                            success = self.recognizer.remove_user(user_to_delete)
                            if success:
                                print(f"âœ… ç”¨æˆ· '{user_to_delete}' å·²åˆ é™¤")
                            else:
                                print(f"âŒ åˆ é™¤ç”¨æˆ· '{user_to_delete}' å¤±è´¥")
                        else:
                            print("å·²å–æ¶ˆåˆ é™¤")
                    else:
                        print("âŒ æ— æ•ˆçš„ç”¨æˆ·ç¼–å·")

                except ValueError:
                    print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")

            elif choice == "3":
                confirm = input("âš ï¸  ç¡®å®šè¦æ¸…ç©ºæ‰€æœ‰ç”¨æˆ·æ•°æ®å—ï¼Ÿæ­¤æ“ä½œä¸å¯æ¢å¤ï¼(y/n): ").strip().lower()
                if confirm == 'y':
                    success = self.recognizer.clear_database()
                    if success:
                        print("âœ… å·²æ¸…ç©ºæ‰€æœ‰ç”¨æˆ·æ•°æ®")
                    else:
                        print("âŒ æ¸…ç©ºå¤±è´¥")
                else:
                    print("å·²å–æ¶ˆæ¸…ç©ºæ“ä½œ")

            elif choice == "4":
                break

            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")

    def run(self):
        """ä¸»è¿è¡Œå‡½æ•°"""
        print("ğŸ¤ å£°çº¹æ³¨å†Œå·¥å…· v1.0")
        print("åŸºäºECAPA-TDNNçš„å£°çº¹è¯†åˆ«ç³»ç»Ÿ")

        while True:
            print("\n" + "="*50)
            print("ä¸»èœå•")
            print("="*50)
            print("1. ğŸ“ äº¤äº’å¼æ³¨å†Œç”¨æˆ·")
            print("2. ğŸ“ æ‰¹é‡æ³¨å†Œï¼ˆä»éŸ³é¢‘æ–‡ä»¶ï¼‰")
            print("3. ğŸ‘¥ æŸ¥çœ‹æ³¨å†Œç”¨æˆ·")
            print("4. ğŸ§ª æµ‹è¯•å£°çº¹è¯†åˆ«")
            print("5. âš™ï¸  ç”¨æˆ·ç®¡ç†")
            print("6. ğŸšª é€€å‡º")

            choice = input("\nè¯·é€‰æ‹©åŠŸèƒ½ (1-6): ").strip()

            if choice == "1":
                self.register_user_interactive()

            elif choice == "2":
                user_id = input("è¯·è¾“å…¥ç”¨æˆ·å: ").strip()
                if not user_id:
                    print("âŒ ç”¨æˆ·åä¸èƒ½ä¸ºç©º")
                    continue

                files_input = input("è¯·è¾“å…¥éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆç”¨é€—å·åˆ†éš”ï¼‰: ").strip()
                if not files_input:
                    print("âŒ æ–‡ä»¶è·¯å¾„ä¸èƒ½ä¸ºç©º")
                    continue

                audio_files = [f.strip() for f in files_input.split(",") if f.strip()]
                if not audio_files:
                    print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„æ–‡ä»¶è·¯å¾„")
                    continue

                self.register_user_batch(user_id, audio_files)

            elif choice == "3":
                self.show_registered_users()

            elif choice == "4":
                self.test_recognition()

            elif choice == "5":
                self.manage_users()

            elif choice == "6":
                print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨å£°çº¹æ³¨å†Œå·¥å…·ï¼")
                break

            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")

            # æš‚åœä¸€ä¸‹ï¼Œè®©ç”¨æˆ·çœ‹åˆ°ç»“æœ
            input("\næŒ‰å›è½¦é”®ç»§ç»­...")


def main():
    """ä¸»å‡½æ•°"""
    try:
        tool = SpeakerRegistrationTool()
        tool.run()
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨é€€å‡º...")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()


